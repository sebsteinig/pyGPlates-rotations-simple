{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3f7adc5",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github",
    "tags": []
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sebsteinig/pyGPlates-reconstructions-template/blob/main/pyGPlates_site-reconstructions_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e04fe8-9fb9-4e10-8c80-1143682b3ffc",
   "metadata": {},
   "source": [
    "# pyGPlates site reconstructions\n",
    "Reconstruct paleolocations of present-day locations across the Phanerozoic. PyGplates allows to use some of the functionality of the GUI GPlates software within python scripts. This allows scripting to automatically process many different locations and/or time periods. Different rotation models can be used and are easily exchangeable. I currently use the PALEOMAP rotation model that is consistent to the Bristol Scotese simulations by Paul Valdes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c77a9b-587f-454c-a90a-024912aa4060",
   "metadata": {},
   "source": [
    "## Prelude (only necesseary when running on Google Colab)\n",
    "If running on Google Colab, execute the following cell to download the repo and install pyGPlates on the virtual machine. \n",
    "\n",
    "If running somewhere else, you can execute the whole notebooks and this part will be skipped automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da9750a6-abd1-47fd-a1a4-875982a67d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect if we are running on colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "# configure environment on Colab\n",
    "    import google.colab\n",
    "\n",
    "    # if on Colab, clone the repository to access the data locally\n",
    "    import os\n",
    "    repo = \"pyGPlates-reconstructions-template\"\n",
    "\n",
    "    # clone repo if it does not already exist\n",
    "    if not os.path.exists(repo):\n",
    "        print('cloning GitHub repository '+repo)\n",
    "        !git clone https://github.com/sebsteinig/{repo}.git\n",
    "  \n",
    "    %cd {repo}\n",
    "    \n",
    "    # install pygplates\n",
    "    !sudo apt install ./bin/pygplates_0.36.0_py36_ubuntu-18.04-amd64.deb\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e991c20-c7f3-4233-b143-44411c613f9d",
   "metadata": {},
   "source": [
    "## User input\n",
    "define variables/lists to quickly change inputs to the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44853eaf-bc9c-4f72-8328-a83d9653ffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input csv file (in data directory) with label, modern latitude, modern longitude\n",
    "file_input_sites = 'example_sites.csv'\n",
    "\n",
    "# list of ages (in Ma) for which we want to reconstruct paleolocations for the input sites\n",
    "ages           = ['0', '100', '200', '300']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599af786-b4f7-450d-b80b-884a0c402067",
   "metadata": {},
   "source": [
    "## import pygplates and other packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7c604eb-26b6-45c9-aa30-a255373b6044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# add pygplates to python path\n",
    "if IN_COLAB:\n",
    "    sys.path.insert(0, os.path.abspath('/usr/lib')) # ubuntu VM on colab\n",
    "else:\n",
    "    sys.path.insert(0, os.path.abspath('./bin/pygplates_0.36.0_py37_Darwin-x86_64')) # macOS Intel \n",
    "import pygplates\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f03dcd-f01a-47e6-bcf5-3b6684cf28fa",
   "metadata": {},
   "source": [
    "## load plate model\n",
    "List of available models at http://portal.gplates.org/portal/rotation_models/.\n",
    "Here we are using the 'PALEOMAP PaleoAtlas for GPlates'by Scotese et al. (https://www.earthbyte.org/paleomap-paleoatlas-for-gplates/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "WcMt0hmK_38Q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WcMt0hmK_38Q",
    "outputId": "1ca62e3a-a818-48f8-aea4-d2827f558cdb"
   },
   "outputs": [],
   "source": [
    "# static polygons are the 'partitioning features'\n",
    "static_polygons = pygplates.FeatureCollection('PALEOMAP_Global_Plate_Model/PALEOMAP_PlatePolygons.gpml')\n",
    "# actual rotation model\n",
    "rotation_model=pygplates.RotationModel('PALEOMAP_Global_Plate_Model/PALEOMAP_PlateModel.rot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cea8cfa-504b-4fd2-a6fb-fbe02829d363",
   "metadata": {},
   "source": [
    "## Main code\n",
    "3-step process to reconstruct paleolocations:\n",
    "1. combine input points into feature collection\n",
    "2. assign plate ids to features\n",
    "3. reconstruct paleolocations for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd729772-cf62-44b4-9803-aa4646174491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  ./reconstructions/0Ma  already exists\n",
      "example_sites\n",
      "Paleolocation for Shaffer-Rohling_Core at 0Ma (LAT/LON): 35.8/-98.2\n",
      "Paleolocation for I35_Sycamore_South at 0Ma (LAT/LON): 34.4/-97.1\n",
      "Paleolocation for Kansas_OK_Outcrop at 0Ma (LAT/LON): 36.2/-94.8\n",
      "Paleolocation for Hamsten_Unit_Core at 0Ma (LAT/LON): 36.8/-98.9\n",
      "Paleolocation for Bakken at 0Ma (LAT/LON): 50.8/-110.5\n",
      "Directory  ./reconstructions/100Ma  already exists\n",
      "example_sites\n",
      "Paleolocation for Shaffer-Rohling_Core at 100Ma (LAT/LON): 33.2/-60.8\n",
      "Paleolocation for I35_Sycamore_South at 100Ma (LAT/LON): 31.6/-60.2\n",
      "Paleolocation for Kansas_OK_Outcrop at 100Ma (LAT/LON): 32.8/-57.5\n",
      "Paleolocation for Hamsten_Unit_Core at 100Ma (LAT/LON): 34.3/-61.1\n",
      "Paleolocation for Bakken at 100Ma (LAT/LON): 50.1/-66.0\n",
      "Directory  ./reconstructions/200Ma  already exists\n",
      "example_sites\n",
      "Paleolocation for Shaffer-Rohling_Core at 200Ma (LAT/LON): 15.2/-40.1\n",
      "Paleolocation for I35_Sycamore_South at 200Ma (LAT/LON): 13.7/-39.1\n",
      "Paleolocation for Kansas_OK_Outcrop at 200Ma (LAT/LON): 15.6/-37.1\n",
      "Paleolocation for Hamsten_Unit_Core at 200Ma (LAT/LON): 16.2/-40.6\n",
      "Paleolocation for Bakken at 200Ma (LAT/LON): 30.6/-48.8\n",
      "Directory  ./reconstructions/300Ma  already exists\n",
      "example_sites\n",
      "Paleolocation for Shaffer-Rohling_Core at 300Ma (LAT/LON): -3.2/-30.7\n",
      "Paleolocation for I35_Sycamore_South at 300Ma (LAT/LON): -4.9/-30.8\n",
      "Paleolocation for Kansas_OK_Outcrop at 300Ma (LAT/LON): -4.3/-28.2\n",
      "Paleolocation for Hamsten_Unit_Core at 300Ma (LAT/LON): -2.1/-30.6\n",
      "Paleolocation for Bakken at 300Ma (LAT/LON): 14.1/-28.8\n"
     ]
    }
   ],
   "source": [
    "# load point coordinates\n",
    "df_sites = pd.read_csv('data/' + file_input_sites,sep=',')\n",
    "\n",
    "for ageCount, age in enumerate(ages):\n",
    "    \n",
    "    # Create output directories & all intermediate directories if don't exists\n",
    "    output_dir = './reconstructions/'+ ages[ageCount] + 'Ma'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(\"Directory \" , output_dir ,  \" Created \")\n",
    "    else:    \n",
    "        print(\"Directory \" , output_dir ,  \" already exists\") \n",
    "    \n",
    "    #### step 1: put the points into a feature collection, using Lat,Lon coordinates from dataframe\n",
    "    point_features = []\n",
    "    for index,row in df_sites.iterrows():\n",
    "        point = pygplates.PointOnSphere(float(row.LAT),float(row.LON))\n",
    "        point_feature = pygplates.Feature()\n",
    "        point_feature.set_geometry(point)\n",
    "        point_features.append(point_feature)\n",
    "\n",
    "    ### step 2: assign plate ids to features\n",
    "    # To reconstruct any feature geometries, each feature must have a plate id assigned. If they don't already, \n",
    "    # then the pygplates function 'PlatePartitioner' performs this function (analogous to the 'assign plate ids' \n",
    "    # menu option in GPlates GUI) \n",
    "    partitioned_point_features = pygplates.partition_into_plates(static_polygons, rotation_model, point_features) \n",
    "\n",
    "    ### step 3: reconstruct paleolocations for features\n",
    "    input_file_name = file_input_sites.split('.')[0]\n",
    "\n",
    "    # Results are saved in two different ways:\n",
    "    \n",
    "    # 1. save shape files to disk for later use (e.g. load shapefiles into python script for direct plotting)\n",
    "    pygplates.reconstruct(partitioned_point_features, rotation_model, output_dir + '/' + input_file_name + '_' + ages[ageCount] +'Ma.shp', float(ages[ageCount]))\n",
    "    \n",
    "    # 2. output paleolocations to CSV\n",
    "    reconstructed_feature_geometries = []\n",
    "    pygplates.reconstruct(partitioned_point_features, rotation_model, reconstructed_feature_geometries, float(ages[ageCount]))    \n",
    "    \n",
    "    # create output CSV file\n",
    "    with open(output_dir + '/' + input_file_name + '_' + ages[ageCount] +'Ma.csv', mode='w') as output_file:\n",
    "        output_writer = csv.writer(output_file, delimiter=',')\n",
    "    \n",
    "        # write header\n",
    "        output_writer.writerow(['name', 'modern LAT', 'modern LON', 'reconstructed LAT', 'reconstructed LON', 'age [Ma]'])\n",
    "    \n",
    "        for siteCount, reconstructed_feature_geometry in enumerate(reconstructed_feature_geometries):\n",
    "            paleoLocation = reconstructed_feature_geometry.get_reconstructed_geometry().to_lat_lon()\n",
    "            \n",
    "            # additional output to console for quick check\n",
    "            print('Paleolocation for ' + df_sites.name[siteCount] + ' at ' + ages[ageCount] + 'Ma (LAT/LON): ' + str(round(paleoLocation[0],1)) + '/'+str(round(paleoLocation[1],1)) )\n",
    "        \n",
    "            # write data to CSV\n",
    "            output_writer.writerow([df_sites.name[siteCount], df_sites.LAT[siteCount], df_sites.LON[siteCount], round(paleoLocation[0],2), round(paleoLocation[1],2), ages[ageCount]])  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "provenance": []
  },
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
